                FOL as an Intermediate Representation

FOL is not really a programming language; it's an intermediate
representation for the insides of a compiler.  It happens to print out
like Scheme code, which makes it much easier to read; and it happens
to ship with a direct interpreter, which gives it a semantics that can
be used to verify correctness of transformations; but how else is it
different from any other intermediate representation?

FOL occupies a slot in the architecture of VL and DVL that is parallel
to the place where control flow graphs (CFGs) usually sit in other
compilers.  Like a CFG, FOL source statically exposes as much
information about the dynamic control flow of the program it
represents as it possibly can.  Like a CFG, FOL is therefore amenable
to flow-based optimizations, like elimination of dead variables and
common subexpressions.

Given that fundamental similarity, however, there are a number of
substantial differences.  I compare here to the CFGs in [1], since
those are the ones I know.

- FOL is oriented around expressions, whereas CFGs are oriented around
  instructions.  Expressions have substructure, and the substructures
  have implicit returns, whereas CFG instructions just read stored
  data for their arguments.  Sufficiently aggressive conversion to
  A-normal form erases this difference.

- A complete FOL program is "bigger" than a CFG from [1], because
  those CFGs are all intraprocedural.  FOL procedures are more
  involved than CFG labels because they accept arguments which are
  kept on an implicit stack; the procedure call conventions are not
  represented in FOL.

- A FOL procedure is "smaller" than a CFG from [1] because those CFGs
  contain labels and jumps, and can express (constant-space) loops
  directly in the CFG, whereas a FOL procedure execution always takes
  a bounded number of instructions (except for the effects of calling
  other procedures).

- A FOL procedure is "bigger" than a basic block from [1] because a
  FOL procedure may contain IFs.  So control flow within a FOL
  procedure is not entirely linear, but may contain branches.  Those
  branches, however, must always converge (except, again, for the
  effect for calling other procedures).

- All variables in a CFG are in scope in the entire graph, whereas FOL
  bindings have scope.  This is not an essential difference.

- The CFGs from [1] allow assignments to their variables, whereas FOL
  does not.  This is not an essential difference.

- Except for reading and writing the store, and calls to procedures
  outside the CFG, any CFG from [1] can be executed in constant space
  (but not necessarily constant time).  In contrast, any FOL procedure
  can be executed in constant space and time (except for calls to
  other procedures).

- The CFGs in [1] have access to a read-write, indexable store (which
  is shared with procedures external to the CFG).  FOL procedures do
  not; instead, they may allocate objects in a memory-managed heap,
  pass them to each other, and access their slots.  I don't think this
  is an essential difference; just that the understanding of the
  behavior of control is done with respect to a different level of
  abstraction of the memory system.

- FOL represents constant-space loops implicitly, via tail recursion
  across FOL procedure boundaries.  CFGs represent constant-space
  loops explicitly, by encoding them with branches inside a single
  CFG.  Therefore, restricting an analysis to intraprocedural in FOL
  is a stronger restriction (because it moves loops out of the
  purview), and does more to make the analysis easier to write.

- FOL procedures are amenable to cascading intra-FOL-procedural
  analysis-and-transformation passes.  Traverse the structure of the
  source recursively, carrying down any information you may need from
  the context.  Return the rewritten expression and any information
  about it that you need.  At a LET, analyze either the
  binding-expression or the body first, depending on whether you going
  in the same or the reverse direction as execution will,
  respectively.  At an IF, recur on the predicate and both branches
  and then merge.  CFG basic blocks are also amenable to such passes,
  but are smaller, so the passes are less useful.

- Intra-CFG-procedural analyses require actual graph dataflows,
  because they can express complicated loops.  In this,
  inter-FOL-procedural analyses are similar.  I suspect the latter are
  more complex, however, because of the implicit stack across
  procedure boundaries, and the consequence that any loops do not run
  in constant space.  I have never seen any descriptions of
  inter-CFG-procedural analyses, so I don't know what interesting
  properties they have in common with either intra-CFG-procedural
  analyses or inter-FOL-procedural analyses.

- The FOL representation has the weakness, relative to CFGs, that
  there is no way for a variable to be in scope over a time-unbounded
  extent.  FOL therefore does not capture loop-invariant data, and
  cannot express loop hoisting transformations.  On the other hand, my
  understanding is that since CFGs can already directly express the
  most common bounded-space computations, it is typical for CFG
  compilers to drop tail recursion optimization of CFG procedures (for
  better or for worse).

TODO Reread Appel Chapters 15, 18, and 19 with an eye to improving
FOL.  Remember the equivalence with the form described in 19.7.  With
something analagous to internal definitions, I should be able to
express (some) constant-space loops in FOL, and do all manner of loop
optimizations.  Or I can leave all that to GCC.


[1] Appel, Andrew W.  "Modern Compiler Implementation in ML".
Cambridge University Press, 2004.  Chapter 17.


Appel's book talks about CFGs, SSA form, and "a functional
representation".  If you restrict the latter to tail-calls only and to
not passing functions around as arguments, then it has exactly the
same expressive power as CFGs or SSA form.  FOL intraprocedural is
just that same form, but without those local procedure definitions.

I could match CFGs by introducing an expression for local (recursive)
function definitions with the restriction that such functions may
only be called in tail position.

This restriction would have the effect that anything that looks like a
return either flies into a statically known let binding, or flies out
of the entire FOL-procedure.

The thing that's unique about interprocedural stuff is that control
flows out of a procedure call into a place that's determined by the
place where it flowed in, and we care about tracing the correspondence
(whether it's implemented by watching the control flow explicitly or
by doing some data flow on some token (or continuation function) that
says where to go is immaterial).

The tail-calls-only restriction also means that you can only model
processes that take a bounded amount of modeled storage to execute (to
wit, the number of static variable bindings in the structure).  What I
mean by "modeled" is that the program is still free to accumulate
stuff either by hitting successive locations in the main memory or by
building itself a nice linked functional data structure; but
presumably analyzing what's going on in places that are not
temporaries is beyond the scope of the model (FOL or CFG).

By not providing such local definition facilities, FOL conflates
tail-call-only procedures with full procedures, and pushes them out of
the scope of FOL's intraprocedural analyses.

One of the consequences of this decision is that FOL cannot express loops
and loop optimizations.


FOL intraprocedural: Dataflows on an acyclic control flow graph.  This
implies a bounded execution time and therefore a finite number of
modeled memory bits.  These are easy to do by following a topological
sort of the control flow graph (FOL source happens to store these
graphs in topologically sorted form).  Break the full program into
pieces with acyclic control (FOL procedures) and don't model flows of
control or data across the introduced boundaries.

Appel intraprocedural: Dataflows with a finite number of modeled bits
of data but an arbitrary control flow graph.  Break the whole program
into pieces (procedures) that each only use a finite number of modeled
bits of memory (temporaries), and don't model flows of control or data
across the boundaries of these pieces.

Interprocedural: Dataflows with unbounded modeled locations (because
of the procedure stack) and an arbitrary control flow graph.  Since
this is Turing complete, you can't ever get this "right".  You have to
forget somewhere.


The latter but also tracking context: control will flow out of a
procedure call into a place that is determined by where it flowed into
that procedure call.
- Also, if control flowed from here, then I know this about the data
  that flowed in, which I don't know in general.
- I think you can go quite wild wrt the fineness of the context you
  track.
