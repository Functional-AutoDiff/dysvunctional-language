This is the "prize-winning text" portion of my last attempt to explain
FOL.  I don't quite know what to do with it, so I will leave it here.

The art of analyzing programs is the art of forgetting judiciously.
If you forget nothing at all, your "analysis" will consist exactly of
running the entire program and writing down the answer.  In this case,
you will have "accelerated" the program a great deal, but the analysis
will be very slow (namely the runtime of the program) and its range of
validity will be that one run of that one program, so you will not be
able to reuse it.  If you forget everything, your analysis will
consist of doing nothing, will be very fast and very broadly
applicable, but will permit no improvement to the program you were
analyzing.

Different optimizing analyses are characterized by what they model and
what they forget, and different choices affect the speed of the
analysis, its reusability in different situations, and the amount of
improvement that doing it offers.  These three things are not traded
off immaculately; there are sweet spots in the design space that make
some sets of these choices definitely better than others for large and
predictable classes of programs.  In fact, the very reason we program
at all is that programs can cause computers to do "the same" things
many times, so that describing the task once to a computer is easier
than performing it that many times oneself.

A compiler analysis that forgets the differences between different
instances of such a task but remembers the characteristics that make
this task different from other tasks could execute in time
proportional to the complexity of the task, but yield total
performance improvements proportional to the number of times the task
is performed; if the latter multiple is enough larger than the former,
the analysis is worthwhile.

Every ahead-of-time compiler commits, by its very nature, to at least
one form of forgetting: it must "forget", because it perforce does not
know, the data that the compilee program will operate on at runtime.
Anything that will be read off of disk files or network servers or
command terminals must necessarily be unknown to the compiler.  This
means that ahead-of-time compilation can at most be as slow as the
complexity (in whatever sense is appropriate) of the program being
compiled, must be applicable to any possible runtime data that the
program might be exposed to, and ought to yield optimization fruit if
the program experiences a sufficiently large total runtime.  Choices
made within the design space of ahead-of-time compilers are tradeoffs
within those bounds.

This enforced separation between what is already known and what is yet
to be known leads the mind naturally to the idea of the separation
between "program" and "data".  The "program" is the essentially fixed
thing we are thinking about how to improve, and the "data" is the
stuff that it will operate on in the future, to all possible values of
which we must be applicable.  There are other social and historical
forces that tend to make programs have one kind of structure and data
another; there are phenomena that blur those distinctions, for Lisp's
storied EVAL takes some "data" and causes it to become "program".
Indeed, if one is thinking about the compiler, the compiler itself is
the "program" and the compilee is the "data"; and if the compiler is
self-hosting, then the compiler can also play the role of "data".

Nevertheless, there is a natural separation between "program" and
"data".  The question of which individual atom of a program will be
executed when is called "control flow", and the question of what
journey some datum will take is called "data flow".  Even in the
absence of EVAL, in a higher-order program the control flow is
intertwined with the data flow, because a call site can invoke a
function that flows in through a variable.  In the beginning they
must, therefore, be analyzed together.  This is the job of VL/DVL, and
its peers like CFA (k- or otherwise) [Shivers].

FOL enters the scene after the integrated flow analysis.  The
essential scope-limiting assumption in FOL and its peers is that the
effect of the data flow on the control flow has been studied as far as
it will be, and FOL will study it no more.  Places of course remain
where the data must affect the control, (for example, IF nodes), but
by the time one reaches FOL it is considered good enough to assume
that an IF can go either way, and stop trying to predict which way it
will go.

Once this assumption is made, there remains some set of paths that one
deems it possible that the running program will take --- sequences of
atomic program elements that it may execute.  Trying to write down the
complete list thereof is both futile and brittle, so it must, of
necessity, be approximated.  A natural approximation is a static
Control Flow Graph (CFG) --- a directed graph whose nodes are atomic
program operations and whose edges are possible control transfers
between them.  The set of all the possible paths through such a graph
is one possible approximation to the set of execution paths that will
occur in a running program.

In programs in the wild, the actual control paths in fact have more
structure than a single, history-free CFG will represent.  There are
procedures, and call sites, and the procedures return to their callers
when done; whereas a CFG node for the end of a procedure must of
necessity list all the places where that procedure is called as
possible targets of outward transfers.  In practice, which way control
will go on exit depends on how it entered, but a direct CFG cannot
capture this.  There are several ways to approach this difficulty: one
can introduce additional data tokens that say where to transfer
control next, in which case one is back to data flow affecting control
flow; one can replicate subgraphs of the control flow graph depending
on context, in which case one must somehow decide when to stop, lest
one's CFG grow beyond all bound; one can somehow represent more than
just the graph structure, with the same caveat; or one can just forget
about it, and get coarser analyses.  The choice of whether or not to
model this behavior distinguishes intraprocedural analyses from
interprocedural ones.

If one assumes that one will not model the relationship between where
a procedure was called from and where it will return, the finest-grain
representation for modeling what's left is equivalent to the control
flow graphs taught by Appel [1].

